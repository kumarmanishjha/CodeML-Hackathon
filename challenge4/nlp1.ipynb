{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container {width:100% !important;} </style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container {width:100% !important;} </style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KlrMnO9advPZ"
   },
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "import numpy as np\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "import io, re, string, time, datetime, os\n",
    "from gensim.models import FastText as FT_gensim\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lsB5ONrf5sQb"
   },
   "outputs": [],
   "source": [
    "from gensim.test.utils import get_tmpfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "3lA_FCrlzBqC",
    "outputId": "cbad74ff-c2de-484c-ab77-a9727e8b66f9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Manish\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import LancasterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "colab_type": "code",
    "id": "glXwd8M6qwMP",
    "outputId": "36af7057-2acc-4676-ba79-9acaf6f919ce"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, LSTM, CuDNNLSTM, Embedding, Activation, Dropout,SpatialDropout1D, Bidirectional, Flatten\n",
    "from keras.models import Sequential, Model\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HgIwIdYLdvPc"
   },
   "outputs": [],
   "source": [
    "#Train and test filenames\n",
    "train_file = 'train_posts.csv'\n",
    "test_file1 = 'test_split01.csv'\n",
    "#test_file2 = 'test_split02.csv'\n",
    "\n",
    "#For testing flow of code with less data\n",
    "#train_file = 'test_split01.csv'\n",
    "#test_file1 = 'test_split02.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qCSo0xw8MsBj"
   },
   "outputs": [],
   "source": [
    "#Function to load labelled file in dataframe\n",
    "def load_file(file_name, train_or_val = True):\n",
    "    f1 = open(file_name, 'rt', encoding=\"utf8\")\n",
    "    data = []\n",
    "    target = []\n",
    "    for line in f1:\n",
    "        line = line.strip()\n",
    "        if line and line != '':\n",
    "          if(train_or_val):\n",
    "            target.append(int(line[-1]))\n",
    "            line = line[:-1]\n",
    "          data.append(line)\n",
    "    f1.close()\n",
    "    if(train_or_val):\n",
    "      return data, target\n",
    "    else:\n",
    "      return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "5VOm90wuNult",
    "outputId": "2fbeb745-c2ba-4d29-d3d7-4c9e124dd8b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file: train_posts.csv...\n",
      "Time taken : 3\n"
     ]
    }
   ],
   "source": [
    "t1= datetime.datetime.now()\n",
    "print(\"Loading file: \" +str(train_file) + '...')\n",
    "#train_df = load_file(train_file)\n",
    "train_data, train_y = load_file(train_file)\n",
    "t2 = datetime.datetime.now()\n",
    "print('Time taken : ' +str((t2-t1).seconds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "OsO8vwv17sJ1",
    "outputId": "fe4794f4-1742-412d-8530-e44ea6d3367a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512629, 512629)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data), len(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pkEum_VrdvPm"
   },
   "outputs": [],
   "source": [
    "#Basic preprocessing in the content of each blog\n",
    "def preprocess(content):\n",
    "    re_print = re.compile('[^%s]' % re.escape(string.printable))\n",
    "    punctuation_table = str.maketrans('', '', string.punctuation)\n",
    "    content = content.translate(punctuation_table) #Remove punctuations\n",
    "    content = content.split()\n",
    "    content = [word.lower() for word in content] #lowercase all\n",
    "    content = ['_NUMBER' if word.isnumeric() else word for word in content ] #Replace a number by _NUMBER\n",
    "    #lancaster=LancasterStemmer() #Initialize Stemmer Class \n",
    "    #content = [lancaster.stem(word) for word in content]  #Stemming\n",
    "    lemmatizer = WordNetLemmatizer() #Initialize Lemmatizer class\n",
    "    content = [lemmatizer.lemmatize(word) for word in content]   #Lemmatizing\n",
    "    content = [re_print.sub('', w) for w in content]\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eMuJeBmzdvPp"
   },
   "outputs": [],
   "source": [
    "#print( 'Unprocessed sample: '  +str (train_data[0])) #Unprocessed sample\n",
    "#print( 'Preprocessed sample: '  +str (preprocess(train_data[0]))) #Preprocessed sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "usgWvp0GQtqw",
    "outputId": "0d8eb25a-e9a2-40e3-d134-e53da42984e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing...\n",
      "Time taken : 303\n"
     ]
    }
   ],
   "source": [
    "#Preprocessing complete train data:\n",
    "t1= datetime.datetime.now()\n",
    "print('Preprocessing...')\n",
    "preprocess_data = []\n",
    "for i in range(len(train_data)):\n",
    "  preprocess_data.append(preprocess(train_data[i])) #Preprocessed content\n",
    "\n",
    "t2= datetime.datetime.now()\n",
    "print('Time taken : ' +str((t2-t1).seconds))\n",
    "# Preprocessed train data\n",
    "#train_data[0:2],preprocess_data[0:2], train_y[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "colab_type": "code",
    "id": "waA2UyC6ZsXv",
    "outputId": "475e240b-74b6-44f4-9b46-d76b7771a938"
   },
   "outputs": [],
   "source": [
    "#Training Gensim Fasttext model for learning word embeddings\n",
    "#train_content = './train_content.txt' #Used to read from file\n",
    "#del train_data\n",
    "fname = \"fasttext.model\"\n",
    "if(os.path.exists(fname)):\n",
    "  model_gensim = FT_gensim.load(fname)\n",
    "else:\n",
    "  t1= datetime.datetime.now()\n",
    "  print('Building Gensim Fasttext model for word embeddings...')\n",
    "  model_gensim = FT_gensim(size = 100)  #Instantiate gensim fasttext model\n",
    "  #model_gensim.build_vocab(corpus_file= train_content)\n",
    "  model_gensim.build_vocab(sentences = preprocess_data)\n",
    "  model_gensim.train(\n",
    "    #corpus_file=train_content,\n",
    "    sentences = preprocess_data ,\n",
    "    epochs=model_gensim.epochs,\n",
    "    total_examples=model_gensim.corpus_count, \n",
    "    total_words=model_gensim.corpus_total_words\n",
    "    )\n",
    "  t2= datetime.datetime.now()\n",
    "  print('Time taken : ' +str((t2-t1).seconds))\n",
    "\n",
    "  print('Saving gensim Fasttext model to disk...')\n",
    "  model_gensim.save(fname)\n",
    "  print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "YUUVMixoa2uj",
    "outputId": "b875ddc8-3b56-4fa8-d409-4f5c8359d62f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gensim fasttext model loaded: FastText(vocab=139925, size=100, alpha=0.025)\n"
     ]
    }
   ],
   "source": [
    "print('Gensim fasttext model loaded: '  +str(model_gensim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7ff-Wr-CbK_0"
   },
   "outputs": [],
   "source": [
    "#print('problem' in model_gensim.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rq0fBK2Lbt6N"
   },
   "outputs": [],
   "source": [
    "#model_gensim.wv.most_similar(positive = 'jayhawks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "okbgYB6LoBs5",
    "outputId": "47baf740-15e1-48de-d857-d627dcb12ac3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file: test_split01.csv...\n",
      "Time taken : 0\n",
      "Preprocessing...\n",
      "Time taken : 6\n"
     ]
    }
   ],
   "source": [
    "##Load and preprocess test data\n",
    "t1= datetime.datetime.now()\n",
    "print(\"Loading file: \" +str(test_file1) + '...')\n",
    "test_data1, test_y1 = load_file(test_file1)\n",
    "t2 = datetime.datetime.now()\n",
    "print('Time taken : ' +str((t2-t1).seconds))\n",
    "\n",
    "#Preprocessing complete train data:\n",
    "t1= datetime.datetime.now()\n",
    "print('Preprocessing...')\n",
    "preprocess_test1 = []\n",
    "for i in range(len(test_data1)):\n",
    "  preprocess_test1.append(preprocess(test_data1[i])) #Preprocessed content\n",
    "\n",
    "t2= datetime.datetime.now()\n",
    "print('Time taken : ' +str((t2-t1).seconds))\n",
    "del test_data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gg0laA1Zaczb"
   },
   "outputs": [],
   "source": [
    "#To get average length of content\n",
    "def averageLen(lst):\n",
    "    lengths = [len(i) for i in lst]\n",
    "    return 0 if len(lengths) == 0 else (float(sum(lengths)) / len(lengths)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "MeNGPrMJZ97k",
    "outputId": "bd5a8d66-50e6-4f5f-a69c-1bddd97ef326"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average length of contents in train_posts.csv is: 184.3809129019232\n"
     ]
    }
   ],
   "source": [
    "print('Average length of contents in ' +str(train_file) +' is: ' +str (averageLen(preprocess_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "klmaRzB6bHid"
   },
   "outputs": [],
   "source": [
    "CONTENT_LEN = 300 ##Content length to work with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2018KrgkfQ9m"
   },
   "outputs": [],
   "source": [
    "#word_index = {t[0]: i+1 for i,t in enumerate(vocab.most_common(MAX_NB_WORDS))}\n",
    "word_index = {word: idx+1 for idx,word in enumerate(model_gensim.wv.vocab)}\n",
    "train_seq = [[word_index.get(word, 0) for word in content] for content in preprocess_data]\n",
    "test_seq1 = [[word_index.get(word, 0)  for word in content] for content in preprocess_test1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2RDQckSlQs4V"
   },
   "outputs": [],
   "source": [
    "MAX_NB_WORDS = len(model_gensim.wv.vocab)\n",
    "MAX_SEQUENCE_LENGTH = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fxHsdttZdi0W"
   },
   "outputs": [],
   "source": [
    "# pad sequences\n",
    "train_data = pad_sequences(train_seq, maxlen=MAX_SEQUENCE_LENGTH, padding=\"pre\", truncating=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W7mf_zTuwPr9"
   },
   "outputs": [],
   "source": [
    "train_y = to_categorical(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "soNmqAEvqNCs",
    "outputId": "2ec0dc19-3c53-46ea-e473-264fbc1cbd40"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (512629, 300)\n",
      "Shape of label tensor: (512629, 3)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of data tensor:', train_data.shape)\n",
    "print('Shape of label tensor:', train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "OjOIoaZlqQtV",
    "outputId": "1be76344-b439-4ba9-efa3-35641003bc11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of test_data tensor: (10000, 300)\n"
     ]
    }
   ],
   "source": [
    "test_data1 = pad_sequences(test_seq1, maxlen=MAX_SEQUENCE_LENGTH, padding=\"pre\", truncating=\"post\")\n",
    "print('Shape of test_data tensor:', test_data1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "feISUjgOqX6N"
   },
   "outputs": [],
   "source": [
    "WV_DIM = 100\n",
    "nb_words = min(MAX_NB_WORDS, len(model_gensim.wv.vocab))\n",
    "#We initialize the matrix with random numbers\n",
    "wv_matrix = (np.random.rand(nb_words, WV_DIM) - 0.5) / 5.0\n",
    "for word, i in word_index.items():\n",
    "    if i >= MAX_NB_WORDS:\n",
    "        continue\n",
    "    try:\n",
    "        embedding_vector = model_gensim.wv[word]\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        wv_matrix[i] = embedding_vector\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preprocess_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-ce5ea0809391>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mdel\u001b[0m \u001b[0mpreprocess_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mdel\u001b[0m \u001b[0mpreprocess_test1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mdel\u001b[0m \u001b[0mtrain_seq\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mdel\u001b[0m \u001b[0mtest_seq1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mdel\u001b[0m \u001b[0mword_index\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'preprocess_data' is not defined"
     ]
    }
   ],
   "source": [
    "del preprocess_data\n",
    "del preprocess_test1\n",
    "del train_seq\n",
    "del test_seq1\n",
    "del word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 436
    },
    "colab_type": "code",
    "id": "R01jRgCirfWj",
    "outputId": "5e164369-b37b-415f-9adc-b3a50fc18db2"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Inputs\n",
    "seq_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "\n",
    "wv_layer = Embedding(nb_words,\n",
    "                     WV_DIM,\n",
    "                     mask_zero=False,\n",
    "                     weights=[wv_matrix],\n",
    "                     input_length=MAX_SEQUENCE_LENGTH,\n",
    "                     trainable=False)\n",
    "\n",
    "embedded_sequences = wv_layer(seq_input)\n",
    "\n",
    "# biLSTM\n",
    "embedded_sequences = SpatialDropout1D(0.2)(embedded_sequences)\n",
    "x = Bidirectional(LSTM(64, return_sequences=False, dropout = 0.4))(embedded_sequences)\n",
    "#x = Bidirectional(LSTM(128, return_sequences=False, dropout=0.2, recurrent_dropout=0.2))(embedded_sequences)\n",
    "\n",
    "#x =  LSTM(32, return_sequences=True)(embedded_sequences)  # returns a sequence of vectors of dimension 32\n",
    "#x = LSTM(32, return_sequences=True)(x)  # returns a sequence of vectors of dimension 32\n",
    "x = LSTM(32)(x)\n",
    "'''\n",
    "x = Dense(32, activation=\"relu\")(x)\n",
    "x = Dropout(0.40)(x)\n",
    "x = Dense(16, activation=\"relu\")(x)\n",
    "x = Dropout(0.40)(x)\n",
    "x = Dense(4, activation=\"relu\")(x)\n",
    "x = Dropout(0.40)(x)\n",
    "x = Dense(2, activation=\"relu\")(x)\n",
    "x = Dropout(0.40)(x)'''\n",
    "\n",
    "x = Dense(3, activation=\"sigmoid\")(x)\n",
    "\n",
    "\n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "8zRcKDof02CK",
    "outputId": "d8950022-89b4-4409-fb4b-1bd788c1fcab"
   },
   "outputs": [],
   "source": [
    "# Build the model\n",
    "model = Model(inputs=[seq_input], outputs=x)\n",
    "#model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.001, clipnorm=.25, beta_1=0.7, beta_2=0.99), metrics=['accuracy'])\n",
    "#model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 364
    },
    "colab_type": "code",
    "id": "zccq0JeIjCV8",
    "outputId": "49d0bf15-fe0e-4d92-f91f-56e3dd2c3386"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 193
    },
    "colab_type": "code",
    "id": "cJI7qwW_VzSY",
    "outputId": "a8cce01f-9c85-4ff7-d86c-59ae827bd5ac"
   },
   "outputs": [],
   "source": [
    "hist = model.fit([train_data], train_y, epochs=10, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4VDcY6u_1YU6"
   },
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate([train_data], train_y, verbose=1)\n",
    "print('Accuracy: %f' % (accuracy*100))\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MrySg3gW2ZJx"
   },
   "outputs": [],
   "source": [
    "model.evaluate([test_data1], train_y = to_categorical(test_y1), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OjFvjQhOYCXx"
   },
   "outputs": [],
   "source": [
    "print('Accuracy of last epoch: ' +str(hist.history.get('acc')[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "390pl5VhzM_i"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ISUDKEuvw3Fe"
   },
   "outputs": [],
   "source": [
    "history = pd.DataFrame(hist.history)\n",
    "plt.figure(figsize=(12,12));\n",
    "plt.plot(history[\"loss\"]);\n",
    "plt.plot(history[\"val_loss\"]);\n",
    "plt.title(\"Loss with pretrained word vectors\");\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xAQeU_a6V_vf"
   },
   "source": [
    "**Running on test data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "By5cnddLVon9"
   },
   "outputs": [],
   "source": [
    "#https://drive.google.com/open?id=17yV2rdCXy-xnVPRN6_Jqhbx7gsuTtKlI  #Location of test file\n",
    "download_test = drive.CreateFile({'id': '1y-FLjkLXFzHtDVo24S0-bEBZ6ECqro8Z'})\n",
    "download_test.GetContentFile('test_mystere.csv')\n",
    "test_mystere = 'test_mystere.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dbnNC1vNXXeb"
   },
   "outputs": [],
   "source": [
    "##Load and preprocess test data\n",
    "t1= datetime.datetime.now()\n",
    "print(\"Loading file: \" +str(test_mystere) + '...')\n",
    "test_data1, test_y1 = load_file(test_mystere)\n",
    "t2 = datetime.datetime.now()\n",
    "print('Time taken : ' +str((t2-t1).seconds))\n",
    "\n",
    "#Preprocessing complete train data:\n",
    "t1= datetime.datetime.now()\n",
    "print('Preprocessing...')\n",
    "preprocess_test1 = []\n",
    "for i in range(len(test_data1)):\n",
    "  preprocess_test1.append(preprocess(test_data1[i])) #Preprocessed content\n",
    "\n",
    "t2= datetime.datetime.now()\n",
    "print('Time taken : ' +str((t2-t1).seconds))\n",
    "del test_data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qdXuenvkXtez"
   },
   "outputs": [],
   "source": [
    "#Get word index and pad test data\n",
    "test_seq1 = [[word_index.get(word, 0)  for word in content] for content in preprocess_test1]\n",
    "test_data1 = pad_sequences(test_seq1, maxlen=MAX_SEQUENCE_LENGTH, padding=\"pre\", truncating=\"post\")\n",
    "print('Shape of test_data tensor:', test_data1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UdlDX4XTYF6C"
   },
   "outputs": [],
   "source": [
    "#Prediction\n",
    "pred = model.predict(test_data1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tb1EyFgrYj5R"
   },
   "outputs": [],
   "source": [
    "##Convert matrix output to labels \n",
    "y_pred = []\n",
    "for item in pred:\n",
    "    y_pred.append(np.where(item == 1)[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bcUFmtKA2fny"
   },
   "outputs": [],
   "source": [
    "print(y_pred)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "nlp1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
