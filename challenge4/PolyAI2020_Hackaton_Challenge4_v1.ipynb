{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "PolyAI2020-Hackaton-Challenge4-v1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PljINmlXHPTA"
      },
      "source": [
        "# CHALLENGE 4\n",
        "\n",
        "Steps done: \n",
        "- Load the dataset\n",
        "- NLP Processing: Tokenizing, Cleaning, Normalization\n",
        "- Transform the text to tf-idf features\n",
        "- Train a baseline model (Logistic Regression)\n",
        "- Make a first submission\n",
        "\n",
        "Todo list:\n",
        "- Try pre-trained model like Google Electra model and simpletransformers lib\n",
        "- Try to augment the data with this algo: https://github.com/jasonwei20/eda_nlp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTU76K56D3IL"
      },
      "source": [
        "Check if we are using the GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "EafcxV96D3IL",
        "outputId": "43787817-7f88-4452-a683-0dfea3ecbdcc"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "''"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mF-xvfnwE4JY"
      },
      "source": [
        "#initialize seed to be sure that the results can be reproduced\n",
        "import numpy as np\n",
        "seed = 7\n",
        "np.random.seed(seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNirbX8VD3IL",
        "outputId": "c6ec8f08-4286-4ef7-8e08-8acc12f2a2e6"
      },
      "source": [
        "!nvcc --version"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2019 NVIDIA Corporation\n",
            "Built on Sun_Jul_28_19:07:16_PDT_2019\n",
            "Cuda compilation tools, release 10.1, V10.1.243\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67oud63gD3IM"
      },
      "source": [
        "# DATASET CLASS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9Jl2PwkD3IM"
      },
      "source": [
        "#Load packages\n",
        "import os, sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "class Dataset:\n",
        "    \"\"\"Class for loading the dataset\"\"\"\n",
        "    def __init__(self):\n",
        "        self._currPath = os.path.dirname(os.path.abspath(\"__file__\")) #root path of the full the project\n",
        "    \n",
        "    def LoadX(self):\n",
        "        \"\"\"Load the inputs\"\"\"\n",
        "        self._listComments = pd.read_csv(self._currPath+\"/train.txt\", header=None)\n",
        "        commentsNp = np.array(self._listComments)\n",
        "        self._arrayComments = commentsNp\n",
        "    \n",
        "    def LoadY(self):\n",
        "        \"\"\"Load the outputs\"\"\"\n",
        "        self._listLabels = pd.read_csv(self._currPath+\"/train_labels.txt\", header=None)\n",
        "        labelsNp = np.array(self._listLabels)\n",
        "        self._arrayLabels = labelsNp\n",
        "      \n",
        "    def LoadKaggleTest(self):\n",
        "        \"\"\"Load the Kaggle test set\"\"\"\n",
        "        self._listCommentsTest = pd.read_csv(self._currPath+\"/test.txt\", header=None)\n",
        "        commentsTestNp = np.array(self._listCommentsTest)\n",
        "        self._arrayCommentsTest = commentsTestNp\n",
        "    \n",
        "    def GetListComments(self):\n",
        "        \"\"\"Get the list of inputs\"\"\"\n",
        "        return self._listComments\n",
        "    \n",
        "    def GetArrayComments(self):\n",
        "        \"\"\"Get the array of inputs\"\"\"\n",
        "        return self._arrayComments\n",
        "    \n",
        "    def GetListLabels(self):\n",
        "        \"\"\"Get the list of outputs\"\"\"\n",
        "        return self._listLabels\n",
        "    \n",
        "    def GetArrayLabels(self):\n",
        "        \"\"\"Get the array of outputs\"\"\"\n",
        "        return self._arrayLabels\n",
        "    \n",
        "    def GetListCommentsTest(self):\n",
        "        \"\"\"Get the Kaggle test set as a list\"\"\"\n",
        "        return self._listCommentsTest"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4I3aLnZD3IM"
      },
      "source": [
        "def printList(li):\n",
        "    \"\"\"Display the list\"\"\"\n",
        "    print(len(li))\n",
        "    for i in range(len(li)):\n",
        "        print(li[0][i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCnknJr6D3IM"
      },
      "source": [
        "dataset = Dataset()\n",
        "dataset.LoadX()\n",
        "dataset.LoadY()\n",
        "dataset.LoadKaggleTest()\n",
        "#printList(dataset.GetListComments())\n",
        "#printList(dataset.GetListLabels())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EccT4LfJD3IM"
      },
      "source": [
        "# NLP PREPROCESSING\n",
        "Tokenizing the Text: Separate each word from sentences\n",
        "\n",
        "Cleaning Text Data: Removing Stopwords, Lexicon \n",
        "\n",
        "Normalization: a way of processing words that reduces them to their roots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OraJwRznIvdA"
      },
      "source": [
        "Tokenizing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYGkEbw3D3IN"
      },
      "source": [
        "import string\n",
        "import spacy\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "from spacy.lang.en import English\n",
        "\n",
        "# Create our list of punctuation marks\n",
        "punctuations = string.punctuation\n",
        "\n",
        "# Create our list of stopwords\n",
        "nlp = spacy.load(\"en\")\n",
        "stop_words = spacy.lang.en.stop_words.STOP_WORDS\n",
        "\n",
        "# Load English tokenizer, tagger, parser, NER and word vectors\n",
        "parser = English()\n",
        "\n",
        "# Creating our tokenizer function\n",
        "def spacy_tokenizer(sentence):\n",
        "    # Creating our token object, which is used to create documents with linguistic annotations.\n",
        "    mytokens = parser(sentence)\n",
        "\n",
        "    # Lemmatizing each token and converting each token into lowercase\n",
        "    mytokens = [ word.lemma_.lower().strip() if word.lemma_ != \"-PRON-\" else word.lower_ for word in mytokens ]\n",
        "\n",
        "    # Removing stop words\n",
        "    mytokens = [ word for word in mytokens if word not in stop_words and word not in punctuations ]\n",
        "\n",
        "    # return preprocessed list of tokens\n",
        "    return mytokens"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JtFyKEUoD3IN"
      },
      "source": [
        "Cleaning: Remove spaces and converts text into lowercase"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GcFf4o-D3IN"
      },
      "source": [
        "from sklearn.base import TransformerMixin\n",
        "# Custom transformer using spaCy\n",
        "class predictors(TransformerMixin):\n",
        "    def transform(self, X, **transform_params):\n",
        "        # Cleaning Text\n",
        "        return [clean_text(text) for text in X]\n",
        "\n",
        "    def fit(self, X, y=None, **fit_params):\n",
        "        return self\n",
        "\n",
        "    def get_params(self, deep=True):\n",
        "        return {}\n",
        "\n",
        "# Basic function to clean the text\n",
        "def clean_text(text):\n",
        "    # Removing spaces and converting text into lowercase\n",
        "    return text.strip().lower()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KtkfU8HmNxQz"
      },
      "source": [
        "Apply functions to our dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ak58xva7D3IN",
        "outputId": "3c946920-e1c3-44e8-82d7-4d4b2a7c02a6"
      },
      "source": [
        "my_doc = dataset.GetListComments()\n",
        "\n",
        "clean_txt = []\n",
        "for sentence in my_doc[0]:\n",
        "  clean_txt.append(clean_text(sentence))\n",
        "print(clean_txt[0],clean_txt[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bromwell high is a cartoon comedy . it ran at the same time as some other programs about school life  such as  teachers  . my   years in the teaching profession lead me to believe that bromwell high  s satire is much closer to reality than is  teachers  . the scramble to survive financially  the insightful students who can see right through their pathetic teachers  pomp  the pettiness of the whole situation  all remind me of the schools i knew and their students . when i saw the episode in which a student repeatedly tried to burn down the school  i immediately recalled . . . . . . . . . at . . . . . . . . . . high . a classic line inspector i  m here to sack one of your teachers . student welcome to bromwell high . i expect that many adults of my age think that bromwell high is far fetched . what a pity that it isn  t story of a man who has unnatural feelings for a pig . starts out with a opening scene that is a terrific example of absurd comedy . a formal orchestra audience is turned into an insane  violent mob by the crazy chantings of it  s singers . unfortunately it stays absurd the whole time with no general narrative eventually making it just too off putting . even those from the era should be turned off . the cryptic dialogue would make shakespeare seem easy to a third grader . on a technical level it  s better than you might think with some good cinematography by future great vilmos zsigmond . future stars sally kirkland and frederic forrest can be seen briefly .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AIzu4VQMD3IN",
        "outputId": "cd04c4d6-8555-4925-bf1f-fd50500256cc"
      },
      "source": [
        "# Create list of word tokens\n",
        "token_list = []\n",
        "for sentence in clean_txt:\n",
        "  token_list.append(spacy_tokenizer(sentence))\n",
        "print(token_list[0],token_list[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['bromwell', 'high', 'cartoon', 'comedy', 'ran', 'time', 'programs', 'school', 'life', 'teachers', 'years', 'teaching', 'profession', 'lead', 'believe', 'bromwell', 'high', 's', 'satire', 'closer', 'reality', 'teachers', 'scramble', 'survive', 'financially', 'insightful', 'students', 'right', 'pathetic', 'teachers', 'pomp', 'pettiness', 'situation', 'remind', 'schools', 'knew', 'students', 'saw', 'episode', 'student', 'repeatedly', 'tried', 'burn', 'school', 'immediately', 'recalled', 'high', 'classic', 'line', 'inspector', 'm', 'sack', 'teachers', 'student', 'welcome', 'bromwell', 'high', 'expect', 'adults', 'age', 'think', 'bromwell', 'high', 'far', 'fetched', 'pity', 'isn', 't'] ['story', 'man', 'unnatural', 'feelings', 'pig', 'starts', 'opening', 'scene', 'terrific', 'example', 'absurd', 'comedy', 'formal', 'orchestra', 'audience', 'turned', 'insane', 'violent', 'mob', 'crazy', 'chantings', 's', 'singers', 'unfortunately', 'stays', 'absurd', 'time', 'general', 'narrative', 'eventually', 'making', 'putting', 'era', 'turned', 'cryptic', 'dialogue', 'shakespeare', 'easy', 'grader', 'technical', 'level', 's', 'better', 'think', 'good', 'cinematography', 'future', 'great', 'vilmos', 'zsigmond', 'future', 'stars', 'sally', 'kirkland', 'frederic', 'forrest', 'seen', 'briefly']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_X8ojlAD3IN"
      },
      "source": [
        "X = np.array([', '.join(x) for x in token_list])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BvNkiX31D3IN"
      },
      "source": [
        "# TF-IDF\n",
        "\n",
        "TFIDF is a numerical statistic that is intended to reflect how important a word is to a document in a collection or corpus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LL6N4kAsD3IN",
        "outputId": "1b38996f-8fb6-4145-c3ac-db1ecde1fd65"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, TfidfTransformer\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "encoder = preprocessing.LabelEncoder()\n",
        "Y = encoder.fit_transform(dataset.GetArrayLabels())\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.1, random_state=1)\n",
        "\n",
        "print(X_train.shape)\n",
        "\n",
        "from sklearn.pipeline import make_pipeline\n",
        "pipe = make_pipeline(\n",
        "    CountVectorizer(),\n",
        "    TfidfTransformer(),\n",
        ")\n",
        "\n",
        "X_train = pipe.fit_transform(X_train.ravel()) \n",
        "X_test = pipe.transform(X_test)\n",
        "X_testKaggle = pipe.transform(dataset.GetListCommentsTest()[0])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:251: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(15750,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Difgp4pqJCfe"
      },
      "source": [
        "# MLTRAINING MODELS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CO3w6MSjMEJm"
      },
      "source": [
        "##Baseline: Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wJ-rOziD3IN"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import classification_report\n",
        "from collections import Counter\n",
        "\n",
        "def LR():\n",
        "    \"\"\"Train logistic regression model\"\"\"\n",
        "    print(sorted(Counter(y_train).items()))\n",
        "\n",
        "    classifier = LogisticRegression()\n",
        "    classifier.fit(X_train, y_train)\n",
        "    y_pred = classifier.predict(X_test)\n",
        "    print(classification_report(y_test,y_pred))\n",
        "    score = mean_absolute_error(y_test, y_pred)\n",
        "    print(score)\n",
        "    return classifier,y_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BM7tFWstD3IN",
        "outputId": "979b5782-62f4-4a35-86fe-3526b4a418b8"
      },
      "source": [
        "logreg, ypred = LR()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(0, 7866), (1, 7884)]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.89      0.89       884\n",
            "           1       0.89      0.89      0.89       866\n",
            "\n",
            "    accuracy                           0.89      1750\n",
            "   macro avg       0.89      0.89      0.89      1750\n",
            "weighted avg       0.89      0.89      0.89      1750\n",
            "\n",
            "0.112\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NNyZw_iD3IN"
      },
      "source": [
        "preds = logreg.predict(X_testKaggle)\n",
        "#print(preds)\n",
        "np.savetxt(\"preds.csv\", preds, delimiter=\",\",fmt='%s')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2h-mvdkD3IN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}